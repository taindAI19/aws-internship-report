---
title: "Translated Blogs"
weight: 3
chapter: false
pre: " <b> 3. </b> "
---

###  [Blog 1 - AWS named as a Leader in 2025 Gartner Magic Quadrant for Cloud-Native Application Platforms and Container Management](3.1-Blog1/)
This blog announces that AWS has been recognized by Gartner as a Leader in the 2025 Magic Quadrant for both Cloud-Native Application Platforms and Container Management. The post highlights AWS’s strong execution and comprehensive vision in helping enterprises build, deploy, and manage cloud-native applications. AWS offers a rich portfolio of services such as AWS Lambda, App Runner, Amazon ECS, Amazon EKS, and AWS Fargate, enabling customers to develop applications that are flexible, scalable, and efficient across cloud and hybrid environments. The blog also reaffirms AWS’s commitment to continued innovation—delivering modern AI/ML tools and container solutions that meet the diverse needs of customers worldwide.

###  [Blog 2 - Automate and orchestrate Amazon EMR jobs using AWS Step Functions and Amazon EventBridge](3.2-Blog2/)
This blog demonstrates how to build a fully automated and cost-efficient Apache Spark data processing pipeline on Amazon EMR using AWS Step Functions and Amazon EventBridge. The solution automatically provisions temporary EMR clusters on EC2, runs Spark jobs, stores results in Amazon S3, and terminates clusters upon completion—reducing operational costs and eliminating manual intervention. The post walks through an example using public COVID-19 data to calculate monthly hospital bed and ICU utilization metrics by state. It also provides detailed guidance on deploying the infrastructure with AWS CloudFormation, configuring EventBridge schedules, monitoring workflows via Step Functions, reviewing CloudWatch logs, and cleaning up resources after execution. This architecture is especially well-suited for periodic workloads such as ETL, batch analytics, and compliance reporting—where fine-grained infrastructure control, high security, and cost optimization are critical.

###  [Blog 3 - Streamline Spark application development on Amazon EMR with the Data Solutions Framework on AWS](3.3-Blog3/)
This blog introduces how to simplify the entire Apache Spark application development lifecycle on Amazon EMR using the AWS Cloud Development Kit (CDK), Data Solutions Framework (DSF), and Amazon EMR Toolkit for VS Code. You’ll learn how to set up a consistent local development environment aligned with production, deploy serverless Spark infrastructure as code (IaC), and build automated CI/CD pipelines for testing and multi-environment deployments. The post walks through packaging a PySpark application as a deployable artifact for EMR Serverless, integrating automated tests with Pytest, and using self-mutating CDK Pipelines to streamline updates. This solution empowers developers with full control over both code and infrastructure, reduces team dependencies, accelerates development cycles, and optimizes Spark workload performance on AWS.
###  [Blog 4 - ...](3.4-Blog4/)
This blog introduces how to start building a data lake in the healthcare sector by applying a microservices architecture. You will learn why data lakes are important for storing and analyzing diverse healthcare data (electronic medical records, lab test data, medical IoT devices…), how microservices help make the system more flexible, scalable, and easier to maintain. The article also guides you through the steps to set up the environment, organize the data processing pipeline, and ensure compliance with security & privacy standards such as HIPAA.

###  [Blog 5 - ...](3.5-Blog5/)
This blog introduces how to start building a data lake in the healthcare sector by applying a microservices architecture. You will learn why data lakes are important for storing and analyzing diverse healthcare data (electronic medical records, lab test data, medical IoT devices…), how microservices help make the system more flexible, scalable, and easier to maintain. The article also guides you through the steps to set up the environment, organize the data processing pipeline, and ensure compliance with security & privacy standards such as HIPAA.

###  [Blog 6 - ...](3.6-Blog6/)
This blog introduces how to start building a data lake in the healthcare sector by applying a microservices architecture. You will learn why data lakes are important for storing and analyzing diverse healthcare data (electronic medical records, lab test data, medical IoT devices…), how microservices help make the system more flexible, scalable, and easier to maintain. The article also guides you through the steps to set up the environment, organize the data processing pipeline, and ensure compliance with security & privacy standards such as HIPAA.
